# AI Document Execution Framework (Safe Use Edition)

## 0. Purpose of This Document

This document exists to **reduce friction for first-time or general users**
while preserving the core principle:

> **Humans decide. AI executes.**

This is **not a creativity engine**  
and **not an automation shortcut**.

It is a **thinking support framework**.

---

## 1. Who This Is For (and Who It Is Not)

### Intended Users

- Professionals who:
  - must take responsibility for outputs
  - work with incomplete or evolving intentions
  - need structure more than speed

### Not Intended For

- Users seeking:
  - instant answers
  - full delegation of thinking
  - AI-led decision making

If you want the AI to “just do it for you”,  
this framework will feel inefficient.

---

## 2. Common Friction Points (Acknowledged)

This framework may feel uncomfortable at first.

Common reactions include:

- “Why doesn’t the AI just fill in the gaps?”
- “Why do I have to define direction?”
- “This feels slower than usual AI usage.”

These reactions are **expected** and **intentional**.

They indicate that **responsibility remains with the human**.

---

## 3. Two Operating Modes (Choose One)

To reduce entry barriers, this framework supports **two modes**.

### Mode A: Assisted Clarification (Beginner-Friendly)

Use when:

- your intent is vague
- you are unsure what to ask yet

AI is allowed to:

- ask clarifying questions
- suggest possible directions
- reframe unclear intent

AI is NOT allowed to:

- finalize decisions
- assume intent
- judge correctness

### Mode B: Strict Execution (Advanced Use)

Use when:

- direction is already clear
- structural fidelity matters

AI is allowed to:

- execute instructions precisely
- maintain format and structure

AI is NOT allowed to:

- expand scope
- add interpretation
- introduce new intent

---

## 4. Minimal Responsibility Contract

Before using this framework, acknowledge:

- AI output is **never final authority**
- AI does not own responsibility
- All acceptance, rejection, and reuse decisions belong to the human

This is not legal language.
This is an **operational boundary**.

---

## 5. Safe Use Guidelines

To avoid stagnation or frustration:

- If you feel stuck → switch to _Assisted Clarification_
- If results feel diluted → switch to _Strict Execution_
- If nothing progresses → your intent may not be ready yet

In that case:

> Stop. Think. Return later.

This framework does not reward forced progress.

---

## 6. Creative Work Notice

This framework prioritizes:

- clarity
- structure
- responsibility

It may reduce:

- randomness
- unexpected inspiration

For pure ideation or brainstorming,
use a different AI interaction style.

---

## 7. Why This Framework Exists

Most AI usage fails not because AI is weak,
but because **responsibility is unclear**.

This framework exists to make responsibility explicit.

If that feels heavy,
it means the framework is working as designed.

---

## 8. Final Note

This document is not a restriction.
It is a **boundary**.

Boundaries protect both:

- human judgment
- AI usefulness

Use it when that protection matters.
