# AI Document Execution Framework

## Before You Start

This repository is **not** about:

- control theory or ML code
- making AI more friendly
- delegating thinking
- getting instant answers

This repository exists for people who have felt at least one of the following:

- AI outputs look reasonable, but feel _uncomfortable_
- Responsibility for the result feels unclear
- AI seems to decide _too much_
- You want to use AI **without losing judgment**

If none of this resonates,  
this framework may not be useful to you.

---

## What This Framework Is

This is a **thinking execution framework**.

- Humans define direction.
- AI executes.
- Responsibility never moves.

AI is treated as a probabilistic execution engine,  
not a partner, not a co-author, not a decision-maker.

---

## What This Framework Is NOT

This framework is **not suitable** if you expect AI to:

- infer intent for you
- decide correctness
- optimize judgment
- replace responsibility

If you want AI to “just handle it”,  
you should stop here.

---

## How to Use This Repository

This repository is structured in three layers.

### 1. Entry Layer — README.md (this file)

Purpose:

- understand whether this framework fits you
- self-select before going deeper

No execution happens here.

---

### 2. Core Layer — system_core.md

Purpose:

- define strict operational boundaries
- establish execution rules
- remove ambiguity

This is the **non-negotiable core**.

You do not modify this unless you fully understand it.

---

### 3. Execution Layer — doc_cloner.md

Purpose:

- apply the framework to actual work
- clone or reconstruct documents
- execute under strict control

This is where AI is allowed to operate.

---

## Two Ways to Approach This Framework

### Option A: Assisted Clarification

Use this when:

- your intent exists but is not fully verbalized
- you need help structuring direction

AI may ask questions.
AI may suggest structure.
AI does **not** decide.

---

### Option B: Strict Execution

Use this when:

- direction is clear
- structure matters more than speed

AI executes exactly.
No interpretation.
No expansion.

---

## A Note on Discomfort

If this framework feels slower or heavier than usual AI usage,  
that is expected.

The friction exists to prevent:

- responsibility leakage
- silent decision transfer
- over-trusting probabilistic output

This framework prioritizes **clarity over comfort**.

---

## When NOT to Use This Framework

Do not use this framework for:

- brainstorming
- free ideation
- creative exploration

Use other tools for that.

This framework is for moments when **judgment matters**.

---

## Final Note

This is not a restriction.
It is a boundary.

Boundaries protect judgment.

If you value that,
continue.

If not,
this repository is not for you.
